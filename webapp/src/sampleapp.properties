#list of valid credentials (comma-separated)
credentials=admin@admin123,user2@password2
#the initial directory path on the server where user will start to select a disk image file
files.dir.path=/usr/share/texas-pete
#command script to execute on the server (Usage: tpkickoff.sh <job name> <selected image file> <pipeline_jar_dir>)
command.script=/usr/share/texas-pete/tpkickoff.sh
#pipeline_jar_dir argument for command to execute on the server (Usage: tpkickoff.sh <job name> <selected image file> <pipeline_jar_dir>)
command.jar=/usr/share/texas-pete/pipeline
#HDFS path for report ($hash means hash of disk image)
report.hdfs.pattern=/texaspete/data/$hash/reports.zip
#URL for hadoop webservice to download a file in HDFS, $file means file to download (replace each / in file path with %2F first)
report.ws.pattern=http://hercules:50075/streamFile?filename=$file&delegation=null
#path (set $PATH, make sure to include path to fsrip. When ProcessBuilder() is created, $PATH is null!)
command.path=:/home/ihelmke/projects/fsrip/build/src
#set command working directory
command.work_dir=/usr/share/texas-pete
#set $LD_LIBRARY_PATH (for fsrip)
command.fsrip.lib=/home/ihelmke/projects/fsrip/deps/lib
#set hadoop home (set $HADOOP_HOME)
command.hadoop.home=/usr/lib/hadoop
#column names for the "job monitor" page (comma-separated)
columns=job name,image id,current task,task status,time started,task map progress,task reduce progress
#local path on the server for "report link" ($hash means hash of disk image). [NO LONGER USED]
#report.local.pattern=
